{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91ba946f-7499-4cda-ae91-cd273f5f519b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pymupdf in /home/jupyter-st125457/.local/lib/python3.12/site-packages (1.25.3)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: unstructured[markdown] in /home/jupyter-st125457/.local/lib/python3.12/site-packages (0.16.25)\n",
      "\u001b[33mWARNING: unstructured 0.16.25 does not provide the extra 'markdown'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: chardet in /home/jupyter-st125457/.local/lib/python3.12/site-packages (from unstructured[markdown]) (5.2.0)\n",
      "Requirement already satisfied: filetype in /home/jupyter-st125457/.local/lib/python3.12/site-packages (from unstructured[markdown]) (1.2.0)\n",
      "Requirement already satisfied: python-magic in /home/jupyter-st125457/.local/lib/python3.12/site-packages (from unstructured[markdown]) (0.4.27)\n",
      "Requirement already satisfied: lxml in /home/jupyter-st125457/.local/lib/python3.12/site-packages (from unstructured[markdown]) (5.3.1)\n",
      "Requirement already satisfied: nltk in /home/jupyter-st125457/.local/lib/python3.12/site-packages (from unstructured[markdown]) (3.9.1)\n",
      "Requirement already satisfied: requests in /opt/tljh/user/lib/python3.12/site-packages (from unstructured[markdown]) (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/tljh/user/lib/python3.12/site-packages (from unstructured[markdown]) (4.12.3)\n",
      "Requirement already satisfied: emoji in /home/jupyter-st125457/.local/lib/python3.12/site-packages (from unstructured[markdown]) (2.14.1)\n",
      "Requirement already satisfied: dataclasses-json in /home/jupyter-st125457/.local/lib/python3.12/site-packages (from unstructured[markdown]) (0.6.7)\n",
      "Requirement already satisfied: python-iso639 in /home/jupyter-st125457/.local/lib/python3.12/site-packages (from unstructured[markdown]) (2025.2.18)\n",
      "Requirement already satisfied: langdetect in /home/jupyter-st125457/.local/lib/python3.12/site-packages (from unstructured[markdown]) (1.0.9)\n",
      "Requirement already satisfied: numpy<2 in /home/jupyter-st125457/.local/lib/python3.12/site-packages (from unstructured[markdown]) (1.26.4)\n",
      "Requirement already satisfied: rapidfuzz in /home/jupyter-st125457/.local/lib/python3.12/site-packages (from unstructured[markdown]) (3.12.2)\n",
      "Requirement already satisfied: backoff in /home/jupyter-st125457/.local/lib/python3.12/site-packages (from unstructured[markdown]) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/tljh/user/lib/python3.12/site-packages (from unstructured[markdown]) (4.12.2)\n",
      "Requirement already satisfied: unstructured-client in /home/jupyter-st125457/.local/lib/python3.12/site-packages (from unstructured[markdown]) (0.31.1)\n",
      "Requirement already satisfied: wrapt in /home/jupyter-st125457/.local/lib/python3.12/site-packages (from unstructured[markdown]) (1.17.2)\n",
      "Requirement already satisfied: tqdm in /opt/tljh/user/lib/python3.12/site-packages (from unstructured[markdown]) (4.66.5)\n",
      "Requirement already satisfied: psutil in /opt/tljh/user/lib/python3.12/site-packages (from unstructured[markdown]) (5.9.8)\n",
      "Requirement already satisfied: python-oxmsg in /home/jupyter-st125457/.local/lib/python3.12/site-packages (from unstructured[markdown]) (0.0.2)\n",
      "Requirement already satisfied: html5lib in /home/jupyter-st125457/.local/lib/python3.12/site-packages (from unstructured[markdown]) (1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/tljh/user/lib/python3.12/site-packages (from beautifulsoup4->unstructured[markdown]) (2.6)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/jupyter-st125457/.local/lib/python3.12/site-packages (from dataclasses-json->unstructured[markdown]) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/jupyter-st125457/.local/lib/python3.12/site-packages (from dataclasses-json->unstructured[markdown]) (0.9.0)\n",
      "Requirement already satisfied: six>=1.9 in /opt/tljh/user/lib/python3.12/site-packages (from html5lib->unstructured[markdown]) (1.17.0)\n",
      "Requirement already satisfied: webencodings in /opt/tljh/user/lib/python3.12/site-packages (from html5lib->unstructured[markdown]) (0.5.1)\n",
      "Requirement already satisfied: click in /home/jupyter-st125457/.local/lib/python3.12/site-packages (from nltk->unstructured[markdown]) (8.1.8)\n",
      "Requirement already satisfied: joblib in /home/jupyter-st125457/.local/lib/python3.12/site-packages (from nltk->unstructured[markdown]) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/jupyter-st125457/.local/lib/python3.12/site-packages (from nltk->unstructured[markdown]) (2024.11.6)\n",
      "Requirement already satisfied: olefile in /home/jupyter-st125457/.local/lib/python3.12/site-packages (from python-oxmsg->unstructured[markdown]) (0.47)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/tljh/user/lib/python3.12/site-packages (from requests->unstructured[markdown]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/tljh/user/lib/python3.12/site-packages (from requests->unstructured[markdown]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/tljh/user/lib/python3.12/site-packages (from requests->unstructured[markdown]) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/tljh/user/lib/python3.12/site-packages (from requests->unstructured[markdown]) (2024.12.14)\n",
      "Requirement already satisfied: aiofiles>=24.1.0 in /home/jupyter-st125457/.local/lib/python3.12/site-packages (from unstructured-client->unstructured[markdown]) (24.1.0)\n",
      "Requirement already satisfied: cryptography>=3.1 in /opt/tljh/user/lib/python3.12/site-packages (from unstructured-client->unstructured[markdown]) (44.0.0)\n",
      "Requirement already satisfied: eval-type-backport>=0.2.0 in /home/jupyter-st125457/.local/lib/python3.12/site-packages (from unstructured-client->unstructured[markdown]) (0.2.2)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /opt/tljh/user/lib/python3.12/site-packages (from unstructured-client->unstructured[markdown]) (0.28.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in /opt/tljh/user/lib/python3.12/site-packages (from unstructured-client->unstructured[markdown]) (1.6.0)\n",
      "Requirement already satisfied: pydantic>=2.10.3 in /opt/tljh/user/lib/python3.12/site-packages (from unstructured-client->unstructured[markdown]) (2.10.4)\n",
      "Requirement already satisfied: pypdf>=4.0 in /home/jupyter-st125457/.local/lib/python3.12/site-packages (from unstructured-client->unstructured[markdown]) (5.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/tljh/user/lib/python3.12/site-packages (from unstructured-client->unstructured[markdown]) (2.9.0.post0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/jupyter-st125457/.local/lib/python3.12/site-packages (from unstructured-client->unstructured[markdown]) (1.0.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/jupyter-st125457/.local/lib/python3.12/site-packages (from unstructured-client->unstructured[markdown]) (0.4.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/tljh/user/lib/python3.12/site-packages (from cryptography>=3.1->unstructured-client->unstructured[markdown]) (1.17.1)\n",
      "Requirement already satisfied: anyio in /opt/tljh/user/lib/python3.12/site-packages (from httpx>=0.27.0->unstructured-client->unstructured[markdown]) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/tljh/user/lib/python3.12/site-packages (from httpx>=0.27.0->unstructured-client->unstructured[markdown]) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/tljh/user/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured[markdown]) (0.14.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/jupyter-st125457/.local/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured[markdown]) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/tljh/user/lib/python3.12/site-packages (from pydantic>=2.10.3->unstructured-client->unstructured[markdown]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/tljh/user/lib/python3.12/site-packages (from pydantic>=2.10.3->unstructured-client->unstructured[markdown]) (2.27.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/jupyter-st125457/.local/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured[markdown]) (1.0.0)\n",
      "Requirement already satisfied: pycparser in /opt/tljh/user/lib/python3.12/site-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured[markdown]) (2.22)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/tljh/user/lib/python3.12/site-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured[markdown]) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph\n",
    "# !pip install -qU \"langchain[openai]\"\n",
    "!pip install -qU langchain-openai\n",
    "!pip install -qU langchain-core\n",
    "!pip install pymupdf\n",
    "!pip install \"unstructured[markdown]\" --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "828b5d65-6192-40b5-8903-e8667828ab83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping pymupdf as it is not installed.\u001b[0m\u001b[33m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pymupdf\n",
      "  Downloading pymupdf-1.25.3-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
      "Downloading pymupdf-1.25.3-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "Installing collected packages: pymupdf\n",
      "\u001b[33m  WARNING: The script pymupdf is installed in '/home/jupyter-st125457/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "Successfully installed pymupdf-1.25.3\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall pymupdf -y\n",
    "!pip install pymupdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9322fe50-fabc-4df7-bbab-8f2dd60251f6",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3de331b-a8bf-453d-b48d-07cffe0f9f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "# LANGSMITH_TRACING=true\n",
    "# LANGSMITH_ENDPOINT=\"https://api.smith.langchain.com\"\n",
    "# LANGSMITH_API_KEY=\"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\"\n",
    "# LANGSMITH_PROJECT=\"pr-essential-quantity-30\"\n",
    "# OPENAI_API_KEY=\"<your-openai-api-key>\"\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcdcc436-6af7-41aa-8d04-dd3bcb135b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter API key for OpenAI:  ········\n"
     ]
    }
   ],
   "source": [
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55bb4755-d8b2-4e1c-95e7-f36a98b6a788",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cef74520-64db-4203-b087-030ff50d7a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c408524f-18e5-4ad1-94f8-0e931e819eb7",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ab90c4ef-c8d5-4528-86df-617a6d92e6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping unsupported file: .ipynb_checkpoints\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader, PyMuPDFLoader, TextLoader, UnstructuredMarkdownLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Use three sentences maximum and keep the answer as concise as possible.\n",
    "Always write answer in json format: question and answer \n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Load and chunk contents of the blog\n",
    "# loader = WebBaseLoader(\n",
    "#     web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "#     bs_kwargs=dict(\n",
    "#         parse_only=bs4.SoupStrainer(\n",
    "#             class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "#         )\n",
    "#     ),\n",
    "# )\n",
    "# docs = loader.load()\n",
    "\n",
    "# pdf_loader = PyMuPDFLoader(\"./data/ULUGBEK_SHERNAZAROV_CV.pdf\")\n",
    "# docs = pdf_loader.load()\n",
    "\n",
    "folder_path = \"./data/\"\n",
    "all_documents = []\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        loader = PyMuPDFLoader(file_path)  # Load PDFs\n",
    "    elif filename.endswith(\".txt\"):\n",
    "        loader = TextLoader(file_path)  # Load text files\n",
    "    elif filename.endswith(\".md\"):\n",
    "        loader = UnstructuredMarkdownLoader(file_path)  # Load Markdown files\n",
    "    else:\n",
    "        print(f\"Skipping unsupported file: {filename}\")\n",
    "        continue\n",
    "\n",
    "    docs = loader.load()\n",
    "    all_documents.extend(docs)\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(all_documents)\n",
    "\n",
    "# Index chunks\n",
    "_ = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "# Define prompt for question-answering\n",
    "# prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5dfb5d60-ab99-4619-a5a1-06f59040b1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) How old are you?\n",
      "Answer: ```json\n",
      "{\n",
      "  \"question\": \"How old are you?\",\n",
      "  \"answer\": \"I am 23 years old.\"\n",
      "}\n",
      "```\n",
      "\n",
      "2) What is your highest level of education?\n",
      "Answer: ```json\n",
      "{\n",
      "  \"question\": \"What is your highest level of education?\",\n",
      "  \"answer\": \"I am currently pursuing a master's degree in Data Science and Artificial Intelligence at the Asian Institute of Technology.\"\n",
      "}\n",
      "```\n",
      "\n",
      "3) What major or field of study did you pursue during your education?\n",
      "Answer: ```json\n",
      "{\n",
      "  \"question\": \"What major or field of study did you pursue during your education?\",\n",
      "  \"answer\": \"I pursued a bachelor's degree in Computer Science and am currently pursuing a master's degree in Data Science and Artificial Intelligence.\"\n",
      "}\n",
      "```\n",
      "\n",
      "4) How many years of work experience do you have?\n",
      "Answer: ```json\n",
      "{\n",
      "  \"question\": \"How many years of work experience do you have?\",\n",
      "  \"answer\": \"I have approximately 1.5 years of work experience.\"\n",
      "}\n",
      "```\n",
      "\n",
      "5) What type of work or industry have you been involved in?\n",
      "Answer: ```json\n",
      "{\n",
      "  \"question\": \"What type of work or industry have you been involved in?\",\n",
      "  \"answer\": \"I have been involved in the fields of web development, machine learning, data science, and artificial intelligence, specifically focusing on tasks such as model training, data collection, and performance analysis.\"\n",
      "}\n",
      "```\n",
      "\n",
      "6) Can you describe your current role or job responsibilities?\n",
      "Answer: ```json\n",
      "{\n",
      "  \"question\": \"Can you describe your current role or job responsibilities?\",\n",
      "  \"answer\": \"In my current role at StartApp, I handle web development, model training, data collection, model deployment, performance analysis, and client interactions. This diverse range of tasks has contributed significantly to my professional experience.\"\n",
      "}\n",
      "```\n",
      "\n",
      "7) What are your core beliefs regarding the role of technology in shaping society?\n",
      "Answer: ```json\n",
      "{\n",
      "  \"question\": \"What are your core beliefs regarding the role of technology in shaping society?\",\n",
      "  \"answer\": \"I believe that generative AI and diffusion models will significantly influence our future. Technology has the potential to drive innovation, enhance data insights, and improve security in various applications. However, it's crucial to approach these advancements responsibly to ensure they benefit society as a whole.\"\n",
      "}\n",
      "```\n",
      "\n",
      "8) How do you think cultural values should influence technological advancements?\n",
      "Answer: ```json\n",
      "{\n",
      "  \"question\": \"How do you think cultural values should influence technological advancements?\",\n",
      "  \"answer\": \"I don't know.\"\n",
      "}\n",
      "```\n",
      "\n",
      "9) As a master’s student, what is the most challenging aspect of your studies so far?\n",
      "Answer: ```json\n",
      "{\n",
      "  \"question\": \"As a master’s student, what is the most challenging aspect of your studies so far?\",\n",
      "  \"answer\": \"The most challenging aspect has been the understanding that publishing a research paper in a top conference requires significant commitment and dedication, which I underestimated. Although I initially aimed for this, I've shifted my focus to skill development and gaining practical experience instead.\"\n",
      "}\n",
      "```\n",
      "\n",
      "10) What specific research interests or academic goals do you hope to achieve during your time as a master's student?\n",
      "Answer: ```json\n",
      "{\n",
      "  \"question\": \"What specific research interests or academic goals do you hope to achieve during your time as a master's student?\",\n",
      "  \"answer\": \"I hope to develop skills in AI, particularly in generative AI and diffusion models, and aim to publish a research paper in a top conference. My focus also includes gaining industrial experience before considering a PhD. Ultimately, I aim to become more professional in my domain.\"\n",
      "}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"How old are you?\",\n",
    "    \"What is your highest level of education?\",\n",
    "    \"What major or field of study did you pursue during your education?\",\n",
    "    \"How many years of work experience do you have?\",\n",
    "    \"What type of work or industry have you been involved in?\",\n",
    "    \"Can you describe your current role or job responsibilities?\",\n",
    "    \"What are your core beliefs regarding the role of technology in shaping society?\",\n",
    "    \"How do you think cultural values should influence technological advancements?\",\n",
    "    \"As a master’s student, what is the most challenging aspect of your studies so far?\",\n",
    "    \"What specific research interests or academic goals do you hope to achieve during your time as a master's student?\"\n",
    "]\n",
    "\n",
    "# Iterate over the questions and invoke the model\n",
    "for idx, question in enumerate(questions, start=1):\n",
    "    response = graph.invoke({\"question\": question})\n",
    "    print(f\"{idx}) {question}\")\n",
    "    print(f\"Answer: {response['answer']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b707ab14-1102-41fa-bcfa-f3a685304f9d",
   "metadata": {},
   "source": [
    "## Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5f32ae12-135d-4e90-a832-3439bb03de19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import MessagesState, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(MessagesState)\n",
    "\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs\n",
    "\n",
    "# Step 1: Generate an AIMessage that may include a tool-call to be sent.\n",
    "def query_or_respond(state: MessagesState):\n",
    "    \"\"\"Generate tool call for retrieval or respond.\"\"\"\n",
    "    llm_with_tools = llm.bind_tools([retrieve])\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # MessagesState appends messages to state instead of overwriting\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Step 2: Execute the retrieval.\n",
    "tools = ToolNode([retrieve])\n",
    "\n",
    "\n",
    "# Step 3: Generate a response using the retrieved content.\n",
    "def generate(state: MessagesState):\n",
    "    \"\"\"Generate answer.\"\"\"\n",
    "    # Get generated ToolMessages\n",
    "    recent_tool_messages = []\n",
    "    for message in reversed(state[\"messages\"]):\n",
    "        if message.type == \"tool\":\n",
    "            recent_tool_messages.append(message)\n",
    "        else:\n",
    "            break\n",
    "    tool_messages = recent_tool_messages[::-1]\n",
    "\n",
    "    # Format into prompt\n",
    "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
    "    system_message_content = (\n",
    "        \"You are an assistant for question-answering tasks. \"\n",
    "        \"Use the following pieces of retrieved context to answer \"\n",
    "        \"the question. If you don't know the answer, say that you \"\n",
    "        \"don't know. Use three sentences maximum and keep the \"\n",
    "        \"answer concise.\"\n",
    "        \"\\n\\n\"\n",
    "        f\"{docs_content}\"\n",
    "    )\n",
    "    conversation_messages = [\n",
    "        message\n",
    "        for message in state[\"messages\"]\n",
    "        if message.type in (\"human\", \"system\")\n",
    "        or (message.type == \"ai\" and not message.tool_calls)\n",
    "    ]\n",
    "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
    "\n",
    "    # Run\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "from langgraph.graph import END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "graph_builder.add_node(query_or_respond)\n",
    "graph_builder.add_node(tools)\n",
    "graph_builder.add_node(generate)\n",
    "\n",
    "graph_builder.set_entry_point(\"query_or_respond\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"query_or_respond\",\n",
    "    tools_condition,\n",
    "    {END: END, \"tools\": \"tools\"},\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"generate\")\n",
    "graph_builder.add_edge(\"generate\", END)\n",
    "\n",
    "graph = graph_builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2e96f354-c8b0-43c7-a3ba-9a5c883c9bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Who is Ulugbek Shernazarov?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_mUEU2eKqkhWIw7hkiLIyJ9nO)\n",
      " Call ID: call_mUEU2eKqkhWIw7hkiLIyJ9nO\n",
      "  Args:\n",
      "    query: Ulugbek Shernazarov\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'source': 'data/myinfo.txt'}\n",
      "Content: I found the following information about Ulugbek Shernazarov:\n",
      "\n",
      "Ulugbek Shernazarov's LinkedIn Profile Ulugbek Shernazarov is a Machine Learning and Computer Vision Engineer with expertise in developing and deploying AI solutions1. He has a strong foundation in software engineering and a deep understanding of Python, PyTorch, TensorFlow, and Django1. Ulugbek is passionate about leveraging cutting-edge technologies to solve complex problems and create impactful innovations.\n",
      "\n",
      "Source: {'source': 'data/myinfo.txt'}\n",
      "Content: I found the following information about Ulugbek Shernazarov:\n",
      "\n",
      "Ulugbek Shernazarov's LinkedIn Profile Ulugbek Shernazarov is a Machine Learning and Computer Vision Engineer with expertise in developing and deploying AI solutions1. He has a strong foundation in software engineering and a deep understanding of Python, PyTorch, TensorFlow, and Django1. Ulugbek is passionate about leveraging cutting-edge technologies to solve complex problems and create impactful innovations.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Ulugbek Shernazarov is a Machine Learning and Computer Vision Engineer with expertise in developing and deploying AI solutions. He has a strong foundation in software engineering and proficiency in Python, PyTorch, TensorFlow, and Django. He is passionate about using advanced technologies to solve complex problems and create impactful innovations.\n"
     ]
    }
   ],
   "source": [
    "input_message = \"Who is Ulugbek Shernazarov?\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
